{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT-119 Curriculum & Student Performance Analysis (Portfolio-Safe)\n",
    "\n",
    "**Purpose:** Demonstrate an end-to-end analytics workflow on LMS-style assessment data **without publishing any raw student records**.\n",
    "\n",
    "This notebook is intentionally designed to be public:\n",
    "- It does **not** include or load any raw institutional data by default.\n",
    "- It can run on **synthetic sample data** to show methodology and outputs.\n",
    "- When running privately, you may point the pipeline to your own local LMS export.\n",
    "\n",
    "## Outputs\n",
    "- Clean numeric dataset (local only)\n",
    "- Predictor correlations (Spearman ranked; Pearson reference)\n",
    "- Focused correlation heatmap\n",
    "- Chapter-level HW/Quiz aggregates + correlations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup\n",
    "This project uses a script-based pipeline:\n",
    "- `scripts/clean_data.py`\n",
    "- `scripts/correlation_analysis.py`\n",
    "- `scripts/chapter_aggregation.py`\n",
    "\n",
    "Below we demonstrate the workflow using **synthetic data**. Replace the synthetic generation step with a local file path if running privately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# If you want to run on private local data, set a path here (DO NOT commit the file).\n",
    "LOCAL_DATA_PATH = None  # Path('data/private_export.csv') cannot share data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create synthetic LMS-style data (public demo)\n",
    "This mimics a realistic LMS export with:\n",
    "- pre-test\n",
    "- attendance\n",
    "- tutoring\n",
    "- chapter homework + quiz columns\n",
    "- final score as a function of fundamentals + engagement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_synthetic_lms(n=200, seed=7):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    pre = rng.normal(60, 12, n).clip(0, 100)\n",
    "    attend = rng.normal(80, 10, n).clip(0, 100)\n",
    "    tutor = rng.binomial(1, 0.35, n) * rng.normal(85, 8, n).clip(0, 100)\n",
    "\n",
    "    # Foundational chapters influence later chapters\n",
    "    ch12 = (pre * 0.55 + rng.normal(20, 10, n)).clip(0, 100)\n",
    "    ch13 = (pre * 0.50 + rng.normal(25, 10, n)).clip(0, 100)\n",
    "    ch14 = (pre * 0.48 + rng.normal(28, 11, n)).clip(0, 100)\n",
    "    ch15 = (pre * 0.46 + rng.normal(30, 12, n)).clip(0, 100)\n",
    "\n",
    "    ch2_hw = (0.35*attend + 0.50*(ch12+ch13+ch14+ch15)/4 + rng.normal(10, 8, n)).clip(0, 100)\n",
    "    ch2_qz = (0.40*ch2_hw + rng.normal(35, 12, n)).clip(0, 100)\n",
    "\n",
    "    ch3_hw = (0.55*ch2_hw + rng.normal(20, 10, n)).clip(0, 100)\n",
    "    ch3_qz = (0.50*ch3_hw + rng.normal(25, 11, n)).clip(0, 100)\n",
    "\n",
    "    ch4_hw = (0.60*ch3_hw + rng.normal(18, 10, n)).clip(0, 100)\n",
    "    ch4_qz = (0.50*ch4_hw + rng.normal(22, 11, n)).clip(0, 100)\n",
    "\n",
    "    ch5_hw = (0.60*ch4_hw + rng.normal(18, 10, n)).clip(0, 100)\n",
    "    ch5_qz = (0.45*ch5_hw + rng.normal(28, 12, n)).clip(0, 100)\n",
    "\n",
    "    # Final score combines fundamentals + engagement + later chapter mastery\n",
    "    final = (\n",
    "        0.20*pre + 0.20*attend + 0.10*(tutor>0).astype(float)*100 +\n",
    "        0.15*ch2_hw + 0.15*ch3_hw + 0.10*ch4_hw + 0.10*ch5_hw +\n",
    "        rng.normal(0, 6, n)\n",
    "    ).clip(0, 100)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Final Score': final,\n",
    "        'Roll Call Attendance (demo)': attend,\n",
    "        'Tutoring (demo)': tutor,\n",
    "        'MAT 119 Pre-Test (demo)': pre,\n",
    "        'Chapter 1.2 -Real Numbers: HW (demo)': ch12,\n",
    "        'Chapter 1.3 Operations with Real Numbers HW (demo)': ch13,\n",
    "        'Chapter 1.4 Simplifying Algebraic Exp.: HW (demo)': ch14,\n",
    "        'Chapter 1.5 Solving Linear Equations : HW (demo)': ch15,\n",
    "        'Chapter 2.1 Graphs: HW (demo)': ch2_hw,\n",
    "        'Chapter 2 Quiz (demo)': ch2_qz,\n",
    "        'Chapter 3.1 Solving Systems by Graphing :HW (demo)': ch3_hw,\n",
    "        'Chapter 3 Quiz (demo)': ch3_qz,\n",
    "        'Chapter 4.1 Solving Linear Inequalities : HW (demo)': ch4_hw,\n",
    "        'Chapter 4 Quiz (demo)': ch4_qz,\n",
    "        'Chapter 5.1 Exponents HW (demo)': ch5_hw,\n",
    "        'Chapter 5 Quiz (demo)': ch5_qz,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "df = make_synthetic_lms()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Run the pipeline (public demo)\n",
    "We run the same cleaning/correlation/aggregation logic used on real LMS exports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(str(Path('..').resolve() / 'scripts'))\n",
    "\n",
    "from clean_data import CleanConfig, clean_lms_export, build_predictor_view\n",
    "from correlation_analysis import corr_with_final\n",
    "\n",
    "cfg = CleanConfig(final_col='Final Score')\n",
    "clean_numeric = clean_lms_export(df, cfg)\n",
    "predictors_only = build_predictor_view(clean_numeric, cfg)\n",
    "\n",
    "spearman = corr_with_final(predictors_only, 'Final Score', 'spearman').sort_values(key=lambda s: s.abs(), ascending=False)\n",
    "pearson  = corr_with_final(predictors_only, 'Final Score', 'pearson').reindex(spearman.index)\n",
    "\n",
    "pd.DataFrame({'Spearman': spearman, 'Pearson': pearson}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Key takeaways (example)\n",
    "In your real analysis, you will translate the ranked signals into decision-ready insights:\n",
    "- Early foundational mastery correlates strongly with downstream chapter performance\n",
    "- Engagement measures (attendance/tutoring) provide actionable intervention levers\n",
    "- Chapter-level aggregation improves interpretability over raw per-assignment features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running privately on institutional data\n",
    "1) Place your export locally (do not commit it) and add it under `data/`.\n",
    "2) Run:\n",
    "\n",
    "```bash\n",
    "python scripts/clean_data.py --input data/private_export.csv \\\n",
    "  --out outputs/clean_numeric.parquet \\\n",
    "  --predictors-out outputs/predictors_only.parquet\n",
    "\n",
    "python scripts/correlation_analysis.py --input outputs/predictors_only.parquet\n",
    "python scripts/chapter_aggregation.py --input outputs/predictors_only.parquet\n",
    "```\n",
    "\n",
    "Only aggregated outputs and figures should be committed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
